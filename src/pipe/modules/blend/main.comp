#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 0) uniform global_t
{
  uint frame;
} global;

// global uniform stuff about image and roi
layout(std140, set = 0, binding = 1) uniform params_t
{
  int filters;
  float opacity;
  float black;
  float white;
  float noise_a;
  float noise_b;
} params;

layout( // input back buffer
    set = 1, binding = 0
) uniform sampler2D img_in;

layout( // new top layer
    set = 1, binding = 1
) uniform sampler2D img_top;

layout( // mask (single channel)
    set = 1, binding = 2
) uniform sampler2D img_mask;

layout( // output
    set = 1, binding = 3
) uniform writeonly image2D img_out;

// return (mu, sigma2) of local x-trans environment
vec2 gauss_xtrans(ivec2 pos)
{
  // rgb from pattern:
  bool blue_top = ((pos.x/3 + pos.y/3) & 1) > 0;
  pos = (pos/3)*3; // start of block pattern

  float mom1 = 0.0f, mom2 = 0.0f;
#define ADD(x, y)\
  {\
    float g = texelFetch(img_top, pos + ivec2(x, y), 0).r;\
    mom1 += g;\
    mom2 += g * g;\
  }
  ADD(0,0)
  ADD(2,0)
  ADD(1,1)
  ADD(0,2)
  ADD(2,2)
#undef ADD
  mom1 /= 5.0;
  mom2 /= 5.0;

  return vec2(mom1, max(0, mom2 - mom2*mom1));
}

void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  vec3 bck   = texelFetch(img_in,   ipos, 0).rgb;
  vec3 rgb   = texelFetch(img_top,  ipos, 0).rgb;
  // float mask = texelFetch(img_mask, ipos, 0).r;
  float mask = texture(img_mask, ipos/vec2(imageSize(img_out))).r;
  // TODO: switch based on mode, implement blend modes
  // if(global.frame > 0) rgb = mix(rgb, mix(rgb, bck, mask), params.opacity);
  // if(global.frame > 0) rgb = mix(rgb, bck, 1.0 - mask*params.opacity);
  // so now we need to talk about a noise model:
  // TODO: opacity as a sliding average, is this a good idea?
  // TODO: put noise sigma in here?
#if 1
  // float t = clamp(params.opacity-mask, 0, 1);//clamp(params.opacity - m, 0, 1);
  // float t = clamp(min(params.opacity, 1-mask), 0, 1);//clamp(params.opacity - m, 0, 1);
  // float t = clamp(params.opacity*smoothstep(0.0, 1.0, 1.0-mask), 0, 1);
  float t = clamp(params.opacity*(1.0-mask), 0, 1);
#if 0
  // this should only be a last resort thing to suppress rgb artifacts.
  const float sigma_noise = 0.3;
  float d = length(bck - rgb)/sigma_noise;
  t *= 1.-smoothstep(0.2, 3.0, d);
#endif

  if(params.filters == 0)
  {
    // use TAA style box clamping
    // estimate variance from spatial neighbours.
    // this works best for real time anti aliasing, since it will increase
    // the threshold near edges and thus blur more there. for photography,
    // arguably we want the opposite behaviour.
    vec3 mom1 = vec3(0.0f);
    vec3 mom2 = vec3(0.0f);
    const int r = 1;
    for(int yy = -r; yy <= r; yy++) {
      for(int xx = -r; xx <= r; xx++) {
        vec3 c = texelFetch(img_top, ipos + ivec2(xx, yy), 0).rgb;
        mom1 += c;
        mom2 += c * c;
      }
    }
    mom1 /= (2.0 * r + 1) * (2.0 * r + 1);
    mom2 /= (2.0 * r + 1) * (2.0 * r + 1);

    vec3 sigma = sqrt(max(vec3(0), mom2 - mom1 * mom1));
    const float thresh = 1.0;
    // switch this line off to see unshielded warping:
    bck = clamp(bck, max(vec3(0), mom1 - thresh * sigma), mom1 + thresh * sigma);
    if(global.frame > 0) rgb = mix(rgb, bck, t);
  }
  else
  {
    // photography version. magically know our noise variance (measurements):
    // darktable's json:
    // 0.0001291937229155835, 4.607888768089825e-05, 8.72921132754699e-05], "b": [2.45962729009841e-07, 1.42262459226602e-07, 2.2271465553342102e-07]}

    // too high values (allow too much input) gives weird colour cast
    float sigma2 = params.noise_a + 65535.0*max(0, rgb.r - params.black)*params.noise_b;
#if 1 // helps
    // increase for flat areas:
    // TODO: fix for bayer:
    vec2 dist = vec2(1.0);
    if(params.filters == 9)
      dist = gauss_xtrans(ipos); // how flat is the area we're looking at?
    // detect flat by comparing sigma2 (noise model) and dist.y (local surroundings)
    float f = 10*clamp(sigma2 / dist.y, 1.0, 4.0);
#if 0 // does not help
    // envelope to mid tones:
    float g0 = pow((rgb.r - params.black)/(params.white-params.black), 1.0);//1.0/2.2);
    float g1 = pow((bck.r - params.black)/(params.white-params.black), 1.0);//1.0/2.2);
    float env = 1;//smoothstep(0.5, 0.0, g0) * smoothstep(0.5, 0.0, g1);
    f = mix(1.0, f, env);
#endif
    // float f = clamp(10.0*(1.0-smoothstep(sqrt(dist.y), 0.0, 0.006)), 1.0, 10.0);
    sigma2 *= f; // *f;
#endif
    t *= clamp(exp(-0.5*(rgb.r - bck.r)*(rgb.r - bck.r) / sigma2), 0, 1);

    // dunno:
    // t *= 2.0*(1.2-smoothstep(sqrt(dist.y), 0.0, 0.03));
    // this looks good but overall a little more noisy:
    // t *= 1-0.7*clamp(exp(-0.5*(rgb.r - bck.r)*(rgb.r - bck.r) / dist.y), 0, 1);
    // const float thresh = 1.0;
    // bck.r = clamp(bck.r, max(0.0, dist.x - thresh * sqrt(dist.y)), dist.x + thresh * dist.y);
    rgb = mix(rgb, bck, t);
  }
#if 0  // sliding average / full accumulation is:
  // float N = global.frame + 1.0;
  // bck = (N-1.) / N * bck + rgb / N;
#endif
#endif

#if 0 // somehow the theory doesn't fit? mask as sqrt looks terrible indeed
  // bayesian risk for wavelet thresholding is minimised by
  // T = sigma^2 / sigma_noise   where sigma^2 = sigma_signal^2 + sigma_noise^2
  // mask is the L2 distance (of the whole patch) our image vs warped back buffer
  const float sigma_noise = 0.08; // i know that, it's been added synthetically
  const float T = 0.0001*params.opacity / sigma_noise;
  // const float d = length(bck - rgb);
  const float d = mask*mask;//sqrt(mask);
  // const float t = smoothstep(0.0, T, d);
  const float t = clamp((T-d)/T, 0.0, 1.0);
  if(global.frame > 0) rgb = mix(bck, rgb, t);
#endif

  imageStore(img_out, ipos, vec4(rgb, 1));
}

